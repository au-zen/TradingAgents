# TradingAgents æ¨¡å‹é…ç½®å»ºè®®
**æ—¥æœŸ**: 2025å¹´7æœˆ17æ—¥  
**ç‰ˆæœ¬**: v1.2.0  

---

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†TradingAgentsé¡¹ç›®çš„å®Œæ•´æ¨¡å‹é…ç½®å»ºè®®ï¼ŒåŒ…æ‹¬OpenRouterå…è´¹æ¨¡å‹ã€Ollamaæœ¬åœ°æ¨¡å‹ã€embeddingæ¨¡å‹é€‰æ‹©ä»¥åŠå…¶ä»–å…è´¹å¤–éƒ¨APIé…ç½®ã€‚

---

## ğŸŒ OpenRouter å…è´¹æ¨¡å‹æ¨è

### æ¨èæ¨¡å‹ï¼ˆæ”¯æŒFunction Callingï¼‰

#### 1. **Qwen3-30B-A3B (å…è´¹)** â­â­â­â­â­
```yaml
model_id: "qwen/qwen3-30b-a3b:free"
ç‰¹ç‚¹:
  - æ”¯æŒå·¥å…·è°ƒç”¨/å‡½æ•°è°ƒç”¨
  - ä¼˜ç§€çš„ä¸­æ–‡æ”¯æŒ
  - 30Bå‚æ•°ï¼Œæ€§èƒ½å¼ºåŠ²
  - å®Œå…¨å…è´¹
é€‚ç”¨åœºæ™¯: æ·±åº¦æ€è€ƒä»»åŠ¡ã€å¤æ‚åˆ†æ
```

#### 2. **Qwen3-14B (å…è´¹)** â­â­â­â­
```yaml
model_id: "qwen/qwen3-14b:free"
ç‰¹ç‚¹:
  - æ”¯æŒå·¥å…·è°ƒç”¨
  - è‰¯å¥½çš„ä¸­æ–‡æ”¯æŒ
  - 14Bå‚æ•°ï¼Œå¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦
  - å®Œå…¨å…è´¹
é€‚ç”¨åœºæ™¯: å¿«é€Ÿæ€è€ƒä»»åŠ¡ã€å¯¹è¯
```

#### 3. **DeepSeek-R1-Distill-Qwen-14B (å…è´¹)** â­â­â­â­
```yaml
model_id: "deepseek/deepseek-r1-distill-qwen-14b:free"
ç‰¹ç‚¹:
  - æ¨ç†èƒ½åŠ›å¼º
  - æ”¯æŒå·¥å…·è°ƒç”¨
  - ä¸­æ–‡æ”¯æŒä¼˜ç§€
  - å®Œå…¨å…è´¹
é€‚ç”¨åœºæ™¯: å¤æ‚æ¨ç†ã€åˆ†æä»»åŠ¡
```

### å½“å‰é…ç½®æ›´æ–°å»ºè®®
```python
# tradingagents/default_config.py
DEFAULT_CONFIG = {
    # æ¨èå…è´¹æ·±åº¦æ¨¡å‹ï¼ˆæ¨ç†/å¤æ‚ä»»åŠ¡ï¼‰
    "deep_think_llm": "qwen/qwen3-30b-a3b:free",
    # æ¨èå…è´¹å¿«é€Ÿæ¨¡å‹ï¼ˆå¯¹è¯/è½»é‡ä»»åŠ¡ï¼‰
    "quick_think_llm": "qwen/qwen3-14b:free",
    "backend_url": "https://openrouter.ai/api/v1",
}
```

---

## ğŸ–¥ï¸ Ollama æœ¬åœ°æ¨¡å‹æ¨è

### æ¨èæ¨¡å‹ï¼ˆæŒ‰æ€§èƒ½æ’åºï¼‰

#### 1. **Qwen3:14b** â­â­â­â­â­
```bash
ollama pull qwen3:14b
```
- **ä¼˜åŠ¿**: æœ€æ–°Qwen3ç³»åˆ—ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ï¼Œä¸­æ–‡æ”¯æŒä¼˜ç§€
- **å‚æ•°**: 14B
- **å†…å­˜éœ€æ±‚**: ~8GB
- **é€‚ç”¨**: ä¸»è¦æ¨ç†æ¨¡å‹

#### 2. **Qwen3:8b** â­â­â­â­
```bash
ollama pull qwen3:8b
```
- **ä¼˜åŠ¿**: å¹³è¡¡æ€§èƒ½å’Œèµ„æºæ¶ˆè€—
- **å‚æ•°**: 8B
- **å†…å­˜éœ€æ±‚**: ~5GB
- **é€‚ç”¨**: å¿«é€Ÿå“åº”æ¨¡å‹

#### 3. **DeepSeek-R1:14b** â­â­â­â­
```bash
ollama pull deepseek-r1:14b
```
- **ä¼˜åŠ¿**: å¼ºæ¨ç†èƒ½åŠ›ï¼Œé€‚åˆå¤æ‚åˆ†æ
- **å‚æ•°**: 14B
- **å†…å­˜éœ€æ±‚**: ~8GB
- **é€‚ç”¨**: æ·±åº¦åˆ†æä»»åŠ¡

#### 4. **Llama3.1:8b** â­â­â­
```bash
ollama pull llama3.1:8b
```
- **ä¼˜åŠ¿**: ç¨³å®šå¯é ï¼Œå·¥å…·è°ƒç”¨æ”¯æŒå¥½
- **å‚æ•°**: 8B
- **å†…å­˜éœ€æ±‚**: ~5GB
- **é€‚ç”¨**: å¤‡ç”¨æ¨¡å‹

### é…ç½®å»ºè®®
```python
# æœ¬åœ°æ¨¡å‹é…ç½®
OLLAMA_CONFIG = {
    "primary_model": "qwen3:14b",
    "fallback_model": "qwen3:8b",
    "reasoning_model": "deepseek-r1:14b",
    "base_url": "http://localhost:11434"
}
```

---

## ğŸ” Embedding æ¨¡å‹æ¨è

### 1. **nomic-embed-text** (Ollama) â­â­â­â­â­
```bash
ollama pull nomic-embed-text
```
- **ä¼˜åŠ¿**: é«˜æ€§èƒ½ï¼Œå¤§ä¸Šä¸‹æ–‡çª—å£ï¼Œå…è´¹
- **ç»´åº¦**: 768
- **ä¸Šä¸‹æ–‡**: 8192 tokens
- **é€‚ç”¨**: ä¸»è¦embeddingæ¨¡å‹

### 2. **mxbai-embed-large** (Ollama) â­â­â­â­
```bash
ollama pull mxbai-embed-large
```
- **ä¼˜åŠ¿**: æœ€æ–°æŠ€æœ¯ï¼Œæ€§èƒ½ä¼˜ç§€
- **ç»´åº¦**: 1024
- **é€‚ç”¨**: é«˜ç²¾åº¦éœ€æ±‚

### 3. **bge-m3** (Ollama) â­â­â­â­
```bash
ollama pull bge-m3
```
- **ä¼˜åŠ¿**: å¤šè¯­è¨€æ”¯æŒï¼Œä¸­æ–‡å‹å¥½
- **ç»´åº¦**: 1024
- **é€‚ç”¨**: å¤šè¯­è¨€åœºæ™¯

### é…ç½®å»ºè®®
```python
# Embeddingé…ç½®
EMBEDDING_CONFIG = {
    "provider": "ollama",
    "model": "nomic-embed-text:latest",
    "base_url": "http://localhost:11434"
}
```

---

## ğŸŒ å…¶ä»–å…è´¹å¤–éƒ¨APIæ¨è

### 1. **Groq** â­â­â­â­â­
```yaml
æä¾›å•†: Groq
å…è´¹é¢åº¦: æ¯å¤©14,400 requests
æ”¯æŒæ¨¡å‹:
  - llama3-groq-70b-8192-tool-use-preview
  - llama3-groq-8b-8192-tool-use-preview
  - mixtral-8x7b-32768
ç‰¹ç‚¹:
  - æå¿«æ¨ç†é€Ÿåº¦
  - æ”¯æŒå·¥å…·è°ƒç”¨
  - ç¨³å®šå¯é 
APIç«¯ç‚¹: https://api.groq.com/openai/v1
```

### 2. **Together AI** â­â­â­â­
```yaml
æä¾›å•†: Together AI
å…è´¹é¢åº¦: $5 å…è´¹é¢åº¦
æ”¯æŒæ¨¡å‹:
  - meta-llama/Llama-3-70b-chat-hf
  - meta-llama/Llama-3-8b-chat-hf
  - Qwen/Qwen2-72B-Instruct
ç‰¹ç‚¹:
  - å¼€æºæ¨¡å‹ä¸°å¯Œ
  - æ”¯æŒå·¥å…·è°ƒç”¨
  - ä¸­æ–‡æ¨¡å‹æ”¯æŒå¥½
APIç«¯ç‚¹: https://api.together.xyz/v1
```

### 3. **Hugging Face Inference API** â­â­â­â­
```yaml
æä¾›å•†: Hugging Face
å…è´¹é¢åº¦: æ¯æœˆ30,000 tokens
æ”¯æŒæ¨¡å‹:
  - microsoft/DialoGPT-medium
  - Qwen/Qwen2.5-7B-Instruct
  - meta-llama/Llama-3.2-3B-Instruct
ç‰¹ç‚¹:
  - æ¨¡å‹é€‰æ‹©ä¸°å¯Œ
  - å¼€æºå‹å¥½
  - ç¤¾åŒºæ”¯æŒå¼º
APIç«¯ç‚¹: https://api-inference.huggingface.co
```

### 4. **Google AI Studio** â­â­â­
```yaml
æä¾›å•†: Google
å…è´¹é¢åº¦: æ¯åˆ†é’Ÿ15 requests
æ”¯æŒæ¨¡å‹:
  - gemini-1.5-flash
  - gemini-1.5-pro
ç‰¹ç‚¹:
  - Googleæœ€æ–°æ¨¡å‹
  - æ”¯æŒå·¥å…·è°ƒç”¨
  - å¤šæ¨¡æ€æ”¯æŒ
APIç«¯ç‚¹: https://generativelanguage.googleapis.com/v1beta
```

---

## ğŸ” ç¯å¢ƒå˜é‡é…ç½®

### .env æ–‡ä»¶æ¨¡æ¿
```bash
# OpenRouter
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Groq
GROQ_API_KEY=your_groq_api_key_here

# Together AI
TOGETHER_API_KEY=your_together_api_key_here

# Hugging Face
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Google AI Studio
GOOGLE_API_KEY=your_google_api_key_here

# Ollama (æœ¬åœ°)
OLLAMA_BASE_URL=http://localhost:11434

# æ•°æ®æºAPI Keys
AKSHARE_TOKEN=your_akshare_token_here
FINNHUB_API_KEY=your_finnhub_api_key_here
```

### é…ç½®æ–‡ä»¶æ›´æ–°
```python
# tradingagents/default_config.py
import os
from dotenv import load_dotenv

load_dotenv()

DEFAULT_CONFIG = {
    # LLM Provideré…ç½®
    "llm_provider": "openrouter",  # openrouter, groq, together, huggingface, google
    
    # OpenRouteré…ç½®
    "openrouter_api_key": os.getenv("OPENROUTER_API_KEY"),
    "deep_think_llm": "qwen/qwen3-30b-a3b:free",
    "quick_think_llm": "qwen/qwen3-14b:free",
    
    # å¤‡ç”¨APIé…ç½®
    "groq_api_key": os.getenv("GROQ_API_KEY"),
    "together_api_key": os.getenv("TOGETHER_API_KEY"),
    "huggingface_api_key": os.getenv("HUGGINGFACE_API_KEY"),
    "google_api_key": os.getenv("GOOGLE_API_KEY"),
    
    # Embeddingé…ç½®
    "embedding_provider": "ollama",
    "embedding_model": "nomic-embed-text:latest",
    "ollama_base_url": os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
    
    # APIç«¯ç‚¹
    "api_endpoints": {
        "openrouter": "https://openrouter.ai/api/v1",
        "groq": "https://api.groq.com/openai/v1",
        "together": "https://api.together.xyz/v1",
        "huggingface": "https://api-inference.huggingface.co",
        "google": "https://generativelanguage.googleapis.com/v1beta"
    }
}
```

---

## ğŸš€ ä½¿ç”¨å»ºè®®

### 1. **ç”Ÿäº§ç¯å¢ƒé…ç½®**
- ä¸»è¦ä½¿ç”¨: OpenRouter (qwen3-30b-a3b:free)
- å¤‡ç”¨: Groq (llama3-groq-70b-tool-use)
- æœ¬åœ°: Ollama (qwen3:14b)

### 2. **å¼€å‘ç¯å¢ƒé…ç½®**
- ä¸»è¦ä½¿ç”¨: Ollama (qwen3:8b)
- æµ‹è¯•: OpenRouterå…è´¹æ¨¡å‹

### 3. **èµ„æºå—é™ç¯å¢ƒ**
- ä½¿ç”¨: Groq API (é€Ÿåº¦å¿«)
- å¤‡ç”¨: Together AI

### 4. **ç¦»çº¿ç¯å¢ƒ**
- ä½¿ç”¨: Ollamaæœ¬åœ°æ¨¡å‹
- æ¨è: qwen3:8b + nomic-embed-text

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ç±»å‹ | æ¨ç†é€Ÿåº¦ | ä¸­æ–‡æ”¯æŒ | å·¥å…·è°ƒç”¨ | æˆæœ¬ | æ¨èåº¦ |
|---------|---------|---------|---------|------|--------|
| Qwen3-30B (OpenRouter) | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | å…è´¹ | â­â­â­â­â­ |
| Groq Llama3-70B | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | å…è´¹é¢åº¦ | â­â­â­â­ |
| Ollama Qwen3:14b | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | å…è´¹ | â­â­â­â­â­ |
| Together AI Qwen2-72B | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | å…è´¹é¢åº¦ | â­â­â­â­ |

---

**é…ç½®å®Œæˆæ—¶é—´**: 2025å¹´7æœˆ17æ—¥  
**å»ºè®®æ›´æ–°é¢‘ç‡**: æ¯æœˆæ£€æŸ¥ä¸€æ¬¡æ–°æ¨¡å‹  
**ç»´æŠ¤çŠ¶æ€**: æŒç»­æ›´æ–° âœ…
