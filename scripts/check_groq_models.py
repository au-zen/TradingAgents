#!/usr/bin/env python3
"""
æ£€æŸ¥Groq APIå½“å‰å¯ç”¨çš„æ¨¡å‹
"""

import os
import sys
import requests
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = project_root / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"ğŸ“‹ å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
    else:
        print(f"âš ï¸  ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {env_path}")
except ImportError:
    print("âš ï¸  python-dotenvæœªå®‰è£…ï¼Œå°è¯•ç›´æ¥è¯»å–ç¯å¢ƒå˜é‡")

def check_groq_models():
    """æ£€æŸ¥Groq APIå¯ç”¨æ¨¡å‹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    api_key = os.getenv('GROQ_API_KEY')
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°GROQ_API_KEYç¯å¢ƒå˜é‡")
        print("ğŸ’¡ è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®GROQ_API_KEY")
        return False
    
    print("ğŸ” æ£€æŸ¥Groq APIå¯ç”¨æ¨¡å‹...")
    print(f"ğŸ”‘ API Key: {api_key[:10]}...{api_key[-4:]}")
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    try:
        # å°è¯•ä¸åŒçš„APIç«¯ç‚¹
        endpoints = [
            'https://api.groq.com/openai/v1/models',
            'https://api.groq.com/v1/models'
        ]

        response = None
        for endpoint in endpoints:
            print(f"ğŸ”— å°è¯•ç«¯ç‚¹: {endpoint}")
            try:
                response = requests.get(endpoint, headers=headers, timeout=10)
                if response.status_code == 200:
                    print(f"âœ… ç«¯ç‚¹å¯ç”¨: {endpoint}")
                    break
                else:
                    print(f"âŒ ç«¯ç‚¹å¤±è´¥: {endpoint} - {response.status_code}")
            except Exception as e:
                print(f"âŒ ç«¯ç‚¹é”™è¯¯: {endpoint} - {e}")

        if response and response.status_code == 200:
            models_data = response.json()
            models = models_data.get('data', [])
            
            print(f"âœ… æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨ï¼Œå…± {len(models)} ä¸ªæ¨¡å‹")
            print("\nğŸ“‹ å¯ç”¨æ¨¡å‹:")
            print("-" * 80)
            
            # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
            llama_models = []
            mixtral_models = []
            other_models = []
            
            for model in models:
                model_id = model.get('id', '')
                created = model.get('created', 0)
                
                if 'llama' in model_id.lower():
                    llama_models.append((model_id, created))
                elif 'mixtral' in model_id.lower():
                    mixtral_models.append((model_id, created))
                else:
                    other_models.append((model_id, created))
            
            # æ˜¾ç¤ºLlamaæ¨¡å‹
            if llama_models:
                print("\nğŸ¦™ Llamaæ¨¡å‹:")
                for model_id, created in sorted(llama_models):
                    print(f"  - {model_id}")
            
            # æ˜¾ç¤ºMixtralæ¨¡å‹
            if mixtral_models:
                print("\nğŸ”€ Mixtralæ¨¡å‹:")
                for model_id, created in sorted(mixtral_models):
                    print(f"  - {model_id}")
            
            # æ˜¾ç¤ºå…¶ä»–æ¨¡å‹
            if other_models:
                print("\nğŸ”§ å…¶ä»–æ¨¡å‹:")
                for model_id, created in sorted(other_models):
                    print(f"  - {model_id}")
            
            # æ£€æŸ¥é…ç½®ä¸­çš„æ¨¡å‹æ˜¯å¦å¯ç”¨
            print("\n" + "=" * 80)
            print("ğŸ” æ£€æŸ¥é…ç½®ä¸­çš„æ¨¡å‹å¯ç”¨æ€§:")
            
            config_models = [
                "llama3-groq-70b-8192-tool-use-preview",
                "llama3-groq-8b-8192-tool-use-preview", 
                "llama-3.1-70b-versatile",
                "llama-3.1-8b-instant",
                "mixtral-8x7b-32768"
            ]
            
            available_model_ids = [m.get('id', '') for m in models]
            
            for model in config_models:
                if model in available_model_ids:
                    print(f"  âœ… {model} - å¯ç”¨")
                else:
                    print(f"  âŒ {model} - ä¸å¯ç”¨")
                    
                    # å¯»æ‰¾ç›¸ä¼¼çš„æ¨¡å‹
                    similar = []
                    for available in available_model_ids:
                        if any(part in available.lower() for part in model.lower().split('-')):
                            similar.append(available)
                    
                    if similar:
                        print(f"     ğŸ’¡ ç›¸ä¼¼æ¨¡å‹: {', '.join(similar[:3])}")
            
            return True
            
        else:
            if response:
                print(f"âŒ æ‰€æœ‰APIç«¯ç‚¹éƒ½å¤±è´¥ï¼Œæœ€åçŠ¶æ€ç : {response.status_code}")
                print(f"å“åº”: {response.text}")
            else:
                print("âŒ æ— æ³•è¿æ¥åˆ°ä»»ä½•APIç«¯ç‚¹")
            return False
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return False

def test_model_call():
    """æµ‹è¯•æ¨¡å‹è°ƒç”¨"""
    
    api_key = os.getenv('GROQ_API_KEY')
    if not api_key:
        return False
    
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹è°ƒç”¨...")
    
    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    
    # æµ‹è¯•ä¸€ä¸ªç®€å•çš„è°ƒç”¨
    test_models = [
        "llama-3.1-8b-instant",
        "llama3-groq-8b-8192-tool-use-preview",
        "mixtral-8x7b-32768"
    ]
    
    for model in test_models:
        try:
            data = {
                "model": model,
                "messages": [
                    {"role": "user", "content": "Hello, respond with just 'OK'"}
                ],
                "max_tokens": 10,
                "temperature": 0
            }
            
            response = requests.post(
                'https://api.groq.com/openai/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                print(f"  âœ… {model}: {content.strip()}")
                return True
            else:
                print(f"  âŒ {model}: {response.status_code} - {response.text[:100]}")
                
        except Exception as e:
            print(f"  âŒ {model}: {e}")
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Groq APIæ¨¡å‹æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    success = check_groq_models()
    
    if success:
        test_model_call()
        
        print("\n" + "=" * 50)
        print("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("1. ä½¿ç”¨ä¸Šé¢æ˜¾ç¤ºä¸º'å¯ç”¨'çš„æ¨¡å‹")
        print("2. å¦‚æœé…ç½®çš„æ¨¡å‹ä¸å¯ç”¨ï¼Œé€‰æ‹©ç›¸ä¼¼çš„æ›¿ä»£æ¨¡å‹")
        print("3. æ›´æ–°cli/utils.pyä¸­çš„æ¨¡å‹é…ç½®")
        
        return 0
    else:
        print("\nâŒ æ£€æŸ¥å¤±è´¥")
        print("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥GROQ_API_KEYæ˜¯å¦æ­£ç¡®")
        print("2. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("3. ç¡®è®¤GroqæœåŠ¡çŠ¶æ€")
        
        return 1

if __name__ == "__main__":
    sys.exit(main())
